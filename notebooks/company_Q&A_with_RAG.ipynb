{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The implementation of RAG chatbot with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = 'gpt-4o-mini'\n",
    "data_path = '../data/faq_document.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the document and split it into chunks\n",
    "loader = TextLoader(data_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'\n",
    "embedding_function = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vector database and save it disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chuncks: 24\n"
     ]
    }
   ],
   "source": [
    "# load it into Chroma and save to disk\n",
    "db = Chroma.from_documents(docs, embedding_function, persist_directory=persist_directory)\n",
    "\n",
    "print(f\"Number of chuncks: {db._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check RAG chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will my Medical Baseline Allowance transfer to my new address?\n",
      "Yes.  Your Medical Baseline Allowance should automatically transfer to your new address when you stop service at one location and start at another location. We always suggest to review your first full bill at your new home to ensure the allowance transferred properly.\n",
      "#####################\n",
      "You will still be required to meet minimum qualifications for the Medical Baseline Allowance at your new location.  If you have questions about those minimum qualifications, please visit our Medical Baseline Allowance page.\n",
      "If you had the Medical Baseline Allowance at your previous location and the benefit did not transfer to your new location, please contact our Customer Service Department at 1-800-743-5000 and a Customer Service Representative will assist you.\n",
      "#####################\n",
      "Will my CARE discount transfer to my new address?\n",
      "Yes.  Your CARE benefit should automatically transfer to your new address when you stop service at one location and start at another location.\n",
      "You will still be required to meet minimum qualifications for the CARE program at your new location.  If you have questions about those minimum qualifications, please visit our Get Discounts on Your PG&E Bill page.\n",
      "#####################\n"
     ]
    }
   ],
   "source": [
    "# query it\n",
    "query = 'Will my Medical Baseline Allowance transfer to my new address?'\n",
    "docs = db.max_marginal_relevance_search(query, k=3, fetch_k=5)\n",
    "\n",
    "# print results\n",
    "for chunck in docs:\n",
    "    print(chunck.page_content)\n",
    "    print(\"#####################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load vectordb from persist_directory saved above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding_function)\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=llm_name, temperature=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run without memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "You are a friendly and polite Pacific Gas and Electric Company FAQ Chatbot. \n",
    "Please answer user's questions truthfully and only based on the provided data, don't invent anything yourself. \n",
    "If you don't know the answer then kindly ask the user to call at 1-800-743-5000 and speak to a customer service representative.\n",
    "You have access to FAQ page. Here is the data: {context}\"\n",
    "Question: {question}\n",
    "Helpful Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have information about yogurts. If you have questions related to PG&E services or programs, please feel free to ask! Otherwise, you can call 1-800-743-5000 to speak with a customer service representative for assistance.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template)\n",
    "\n",
    "# Run chain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "query = 'Are there yogurts?'\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectordb.as_retriever(search_type=\"mmr\"),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
    "\n",
    "\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add memory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "\n",
    "retriever=vectordb.as_retriever(search_type=\"mmr\")\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, your Medical Baseline Allowance should automatically transfer to your new address when you stop service at one location and start at another location. It's recommended to review your first full bill at your new home to ensure the allowance transferred properly. However, you will still need to meet the minimum qualifications for the Medical Baseline Allowance at your new location.\n"
     ]
    }
   ],
   "source": [
    "question = 'Will my Medical Baseline Allowance transfer to my new address?'\n",
    "result = qa.invoke({\"question\": question})\n",
    "\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the minimum qualifications?\"\n",
    "result = qa.invoke({\"question\": question})\n",
    "\n",
    "print(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
